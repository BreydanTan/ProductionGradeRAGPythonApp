# RAG应用学习指南 - 完整学习路线图

**文档版本**: 1.0
**最后更新**: 2025-11-16
**目标受众**: 初学者到中级开发者
**预期学习周期**: 4-6周

---

## 目录

1. [学习概述](#学习概述)
2. [学习时间线](#学习时间线)
3. [五个学习阶段](#五个学习阶段)
4. [每个阶段详解](#每个阶段详解)
5. [推荐学习路径](#推荐学习路径)
6. [自我评估清单](#自我评估清单)
7. [常见学习陷阱](#常见学习陷阱)

---

## 学习概述

### 这个项目你将学到什么？

本项目是一个完整的生产级RAG（检索增强生成）应用，通过学习它，你将掌握：

✅ **现代Python Web开发**
- FastAPI 异步框架
- Streamlit 前端框架
- 异步编程模式

✅ **AI/机器学习集成**
- OpenAI API 调用
- 向量化和嵌入
- 语义搜索

✅ **系统设计**
- 事件驱动架构（Inngest）
- 向量数据库（Qdrant）
- 生产级错误处理

✅ **完整开发流程**
- 本地开发环境搭建
- Docker 容器化
- 云平台部署

### 为什么这个项目特别？

1. **生产级代码** - 不是玩具项目，是真实可用的应用
2. **完整栈** - 从前端到后端再到数据库
3. **现代技术** - 使用最新的Python和AI技术
4. **循序渐进** - 从理解到动手再到扩展

---

## 学习时间线

```
第1-2周: 环境搭建 + 理解基础概念
       ├─ 1-2 天: 环境配置
       └─ 3-5 天: 学习核心概念

第2-3周: 深入理解系统架构
       ├─ 3-5 天: 代码分析
       ├─ 2-3 天: 数据流程学习
       └─ 2-3 天: API调用测试

第4周: 开发和修改
       ├─ 1 周: 修改功能
       ├─ 3-4 天: 自己实现一个特性
       └─ 2-3 天: 错误处理和优化

第5周: 部署和生产化
       ├─ 2-3 天: Docker 容器化
       ├─ 2-3 天: 云平台部署
       └─ 2-3 天: 监控和维护

第6周+: 功能扩展和深化
       ├─ 多文档对比分析
       ├─ 更复杂的提示工程
       ├─ 性能优化
       └─ 生产环境监控

时间投入建议：
└─ 每周 15-25 小时
└─ 每天 2-4 小时的学习 + 动手
```

---

## 五个学习阶段

### 🚀 第一阶段: 环境搭建（1-2天）

**目标**: 让应用在你的电脑上成功运行

**关键任务**:
- [ ] 安装 Python 3.13+
- [ ] 安装 Node.js 18+
- [ ] 克隆项目到本地
- [ ] 创建虚拟环境
- [ ] 安装依赖包
- [ ] 获取 OpenAI API 密钥
- [ ] 配置 .env 文件
- [ ] 启动所有服务
- [ ] 成功上传一个 PDF
- [ ] 成功提出一个问题

**时间分配**:
- Python 安装: 10 分钟
- Node.js 安装: 10 分钟
- 项目克隆和虚拟环境: 20 分钟
- 依赖安装: 10 分钟
- API 密钥获取: 15 分钟
- 启动应用: 30 分钟
- 测试上传和提问: 15 分钟

**学习资源**:
- 📖 `PROJECT_SPEC_CN.md` 第 6-7 章
- 🎥 本地开发指南
- ✅ 验证步骤在 环境配置指南 部分

**成功标准**:
```
✅ uvicorn 显示 "Uvicorn running on http://127.0.0.1:8000"
✅ streamlit 显示 "Local URL: http://localhost:8501"
✅ 可以打开浏览器访问 http://localhost:8501
✅ 可以上传 PDF 文件
✅ 可以成功提出问题并获得答案
```

---

### 🧠 第二阶段: 理解结构（3-5天）

**目标**: 理解应用如何工作，每个模块的作用

**关键概念**:
1. **RAG 是什么**
   - 检索（Retrieval）
   - 增强（Augmentation）
   - 生成（Generation）

2. **系统的五个核心模块**
   ```
   Streamlit (前端)
       ↓
   FastAPI (后端)
       ↓
   Inngest (事件系统)
       ↓
   Qdrant (向量数据库)
       ↓
   OpenAI (AI 模型)
   ```

3. **两个主要流程**
   - PDF 上传流程
   - 提问和回答流程

**学习活动**:

**Day 1: 理解 RAG 基础**
- [ ] 读 `PROJECT_SPEC_CN.md` 第 1-3 章
- [ ] 画出系统架构图
- [ ] 理解向量数据库的概念
- 时间: 2 小时

**Day 2: 分析 PDF 上传流程**
- [ ] 读 `PROJECT_SPEC_CN.md` 第 4 章 (流程1)
- [ ] 跟踪上传一个 PDF 时发生的事
- [ ] 画出数据流向图
- 时间: 1.5 小时

**Day 3: 分析提问回答流程**
- [ ] 读 `PROJECT_SPEC_CN.md` 第 4 章 (流程2)
- [ ] 跟踪提问时发生的事
- [ ] 比较两个流程的异同
- 时间: 1.5 小时

**Day 4: 学习关键技术**
- [ ] 理解异步编程 (async/await)
- [ ] 理解事件驱动架构
- [ ] 理解向量化和相似度搜索
- 时间: 2 小时

**Day 5: 整体复习和测试**
- [ ] 写一个 1 页纸的系统概述
- [ ] 用自己的话解释每个模块的作用
- [ ] 回答反思问题
- 时间: 1 小时

**反思问题** (用来检查理解):
```
1. 为什么要把 PDF 分成小块？
   答: _________________________________

2. 向量和相似度有什么关系？
   答: _________________________________

3. Inngest 在这个系统中的作用是什么？
   答: _________________________________

4. FastAPI 和 Streamlit 各负责什么？
   答: _________________________________

5. 一次完整的提问到回答需要几个 API 调用？
   答: _________________________________
```

---

### 🔍 第三阶段: 数据流程深入（6-10天）

**目标**: 能够跟踪代码，理解数据如何流动

**关键学习内容**:

**Day 1-2: 代码库导航**
- [ ] 打开 `main.py`，理解每个函数
- [ ] 打开 `streamlit_app.py`，理解 UI 逻辑
- [ ] 打开 `vector_db.py`，理解数据库操作
- [ ] 打开 `data_loader.py`，理解数据处理
- 时间: 3 小时

**Day 3-4: 追踪数据流向**
- [ ] 上传一个 PDF，看后端日志
- [ ] 记录每一步打印的信息
- [ ] 用 Inngest UI 观察函数执行
- [ ] 查看 Qdrant 中储存的数据
- 时间: 3 小时

**Day 5-6: API 调用深入**
- [ ] 理解 OpenAI embedding API
- [ ] 理解 OpenAI chat API
- [ ] 计算一次查询的成本
- [ ] 测试不同的参数效果
- 时间: 3 小时

**Day 7-8: 向量搜索理解**
- [ ] 理解余弦相似度的概念
- [ ] 理解 top_k 参数的影响
- [ ] 用不同的问题测试搜索效果
- [ ] 观察相似度分数
- 时间: 3 小时

**Day 9-10: 错误处理和限流**
- [ ] 理解限流规则如何工作
- [ ] 测试超限情况
- [ ] 理解重试机制
- [ ] 读错误处理代码
- 时间: 2 小时

**实践任务**:

**任务 1: 添加日志追踪**
```python
# 在 main.py 中添加日志来追踪数据流
import logging

logger = logging.getLogger(__name__)

# 在 rag_ingest_pdf 开始处
logger.info(f"Starting PDF ingestion for {source_id}")

# 在关键步骤处添加日志
logger.info(f"Generated {len(chunks)} chunks")
logger.info(f"Embedding {len(chunks)} chunks...")
logger.info(f"Stored {result.ingested} chunks in database")
```

然后上传 PDF，看日志输出。

**任务 2: 修改参数并观察效果**
```python
# 在 data_loader.py 中修改 chunk_size
# 原来: chunk_size=1000
# 修改为: chunk_size=500

# 观察:
# - 生成更多的块
# - 搜索效果如何变化
```

**任务 3: 手动测试 API 调用**
```python
import openai

# 在 Python 终端中
client = openai.OpenAI()

# 测试 embedding
response = client.embeddings.create(
    input="What is machine learning?",
    model="text-embedding-3-large"
)
print(f"Embedding dimension: {len(response.data[0].embedding)}")

# 测试 chat
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are helpful"},
        {"role": "user", "content": "What is RAG?"}
    ]
)
print(response.choices[0].message.content)
```

---

### 💻 第四阶段: 核心功能开发（2-3周）

**目标**: 能够修改和扩展应用功能

**周 1: 理解和修改**

**Day 1-2: 修改现有功能**
- [ ] 修改系统提示词
  ```python
  # 在 main.py 的 rag_query_pdf_ai 函数中
  # 修改 system_prompt 的内容
  system_prompt = "You are a helpful assistant. Answer questions..."
  ```

- [ ] 修改 chunk 大小
  ```python
  # 在 data_loader.py 中
  # 尝试 chunk_size = 1500 或 500
  ```

- [ ] 修改返回段落数
  ```python
  # 在 streamlit_app.py 中
  # 修改 default=5 为其他值
  top_k = st.slider("Number of passages", 1, 20, default=10)
  ```

**Day 3-5: 添加新功能**

**功能 1: 添加文件过滤**
```python
# 在 streamlit_app.py 中，限制上传文件类型
uploaded_file = st.file_uploader(
    "Choose a PDF",
    type=["pdf"]  # 只允许 PDF
)
```

**功能 2: 添加提问历史**
```python
# 在 streamlit_app.py 中
if "history" not in st.session_state:
    st.session_state.history = []

# 每次回答后添加到历史
st.session_state.history.append({
    "question": question,
    "answer": answer
})

# 显示历史
with st.expander("Previous Questions"):
    for item in st.session_state.history:
        st.write(f"Q: {item['question']}")
        st.write(f"A: {item['answer']}")
```

**功能 3: 显示搜索分数**
```python
# 修改 vector_db.py 的 search 方法
# 返回相似度分数

# 在 streamlit_app.py 中显示
st.write("### Relevance Scores")
for i, score in enumerate(search_scores):
    st.write(f"Passage {i+1}: {score:.2f}")
```

**周 2: 性能优化**

**Day 1-2: 理解性能瓶颈**
- [ ] 测量各步骤耗时
  ```python
  import time

  start = time.time()
  # 执行操作
  elapsed = time.time() - start
  logger.info(f"Operation took {elapsed:.2f}s")
  ```

- [ ] 找出最慢的步骤
- [ ] 记录实际性能数据

**Day 3-4: 优化和改进**
- [ ] 批量处理优化
- [ ] 缓存重复结果
- [ ] 异步并发改进

**Day 5: 性能测试和文档**
- [ ] 写一个简单的性能报告
- [ ] 对比优化前后的性能
- [ ] 记录优化方法

**周 3: 错误处理和质量**

**Day 1-3: 错误处理**
- [ ] 处理网络错误
- [ ] 处理 API 超时
- [ ] 处理用户输入错误
- [ ] 添加有用的错误消息

**Day 4-5: 代码质量**
- [ ] 添加类型提示
- [ ] 添加文档字符串
- [ ] 简化复杂函数
- [ ] 添加单元测试

---

### 🚀 第五阶段: 功能扩展（4周+）

**目标**: 添加新功能，使应用更强大

**可选的扩展方向**:

**方向 1: 多文档对比**
```python
# 添加功能: 比较多个 PDF 中对同一问题的答案

"""
用户可以上传多个 PDF，然后问一个问题，
系统返回各个文档中的答案进行对比。
"""

# 新事件: rag/compare_documents
# 输入: 多个 pdf_ids 和一个问题
# 输出: {pdf_id1: answer1, pdf_id2: answer2, ...}
```

**方向 2: 高级提示工程**
```python
# 改进提示词策略

techniques = {
    "few_shot": "提供几个例子让AI学习",
    "chain_of_thought": "让AI逐步思考",
    "role_play": "给AI一个角色",
    "instruction_following": "更具体的指令"
}

# 用户可以选择不同的策略
strategy = st.selectbox("Answer style", techniques.keys())
```

**方向 3: 文档分析工具**
```python
# 添加额外的分析功能

tools = {
    "summary": "自动总结文档",
    "keyword_extraction": "提取关键词",
    "qa_generation": "自动生成 QA 对",
    "outline": "生成文档大纲"
}

# 用户可以选择分析工具
```

**方向 4: 性能和可扩展性**
```python
# 处理更大的文档
# 处理更多并发用户
# 添加缓存层
# 添加监控和告警
```

**方向 5: 多语言支持**
```python
# 支持其他语言的 PDF
# 支持多语言查询
# 自动语言检测

languages = ["English", "Chinese", "Spanish", "French"]
selected_lang = st.selectbox("Select language", languages)
```

**建议的优先级**:
1. 优先级高: 多文档对比、高级提示工程
2. 优先级中: 文档分析、缓存优化
3. 优先级低: 多语言、高级监控

---

## 每个阶段详解

### 第一阶段: 环境搭建详细步骤

#### 步骤 1: 验证 Python 安装
```bash
python --version
# 应该输出 Python 3.13.x 或更高

# 如果没有，从 python.org 下载
```

#### 步骤 2: 验证 Node.js 安装
```bash
node --version
npm --version
# 应该都有版本号输出
```

#### 步骤 3: 克隆项目
```bash
git clone <你的仓库 URL>
cd ProductionGradeRAGPythonApp
```

#### 步骤 4: 创建虚拟环境
```bash
# 方法 A: 使用 venv
python -m venv venv
source venv/bin/activate  # Linux/macOS
# 或
venv\Scripts\activate  # Windows

# 方法 B: 使用 uv (更快)
pip install uv
uv venv
source .venv/bin/activate
```

#### 步骤 5: 安装依赖
```bash
uv pip install
# 或
pip install -r requirements.txt
```

#### 步骤 6: 获取 API 密钥

1. 访问 https://platform.openai.com
2. 注册或登录
3. 点击右上角用户菜单 → "API keys"
4. 点击 "Create new secret key"
5. 复制密钥

#### 步骤 7: 配置 .env
```bash
cat > .env << EOF
OPENAI_API_KEY=sk-proj-你的密钥
EOF

# 验证
cat .env
```

#### 步骤 8: 启动应用

**终端 1 - 启动 Inngest**
```bash
npx inngest-cli@latest dev
```

**终端 2 - 启动后端**
```bash
source venv/bin/activate
uvicorn main:app --reload
```

**终端 3 - 启动前端**
```bash
source venv/bin/activate
streamlit run streamlit_app.py
```

#### 步骤 9: 测试应用
1. 打开浏览器访问 http://localhost:8501
2. 在 uploads/ 目录放一个 PDF 文件
3. 或者用上传器上传 PDF
4. 问一个问题
5. 看是否得到答案

---

## 推荐学习路径

### 路径 1: 快速上手型（2周）

**适合**: 想快速理解应用的开发者

```
Week 1:
  Day 1: 环境搭建
  Day 2-3: 阅读规格文档
  Day 4-5: 跟踪代码执行
  Day 6-7: 尝试修改参数

Week 2:
  Day 1-2: 添加一个简单功能
  Day 3-4: 理解错误处理
  Day 5-7: 复习和总结

产出: 理解应用架构，能进行简单修改
```

### 路径 2: 系统学习型（4周）

**适合**: 想深入掌握每个部分的开发者

```
Week 1: 环境搭建 + 基础理解
Week 2: 系统架构深入学习
Week 3: 代码分析和修改
Week 4: 添加新功能和优化

产出: 能独立修改和扩展应用
```

### 路径 3: 完整掌握型（6周）

**适合**: 想成为这个项目的专家

```
Week 1-2: 基础学习（快速型）
Week 3-4: 深入学习（系统型）
Week 5: 性能优化和扩展
Week 6: 部署和生产化

产出: 能独立部署、维护和扩展应用
```

---

## 自我评估清单

### 第一阶段评估

**环境搭建完成度**:
- [ ] Python 和 Node.js 已安装
- [ ] 虚拟环境已创建
- [ ] 依赖已安装
- [ ] API 密钥已配置
- [ ] 三个服务都能成功启动
- [ ] 能访问前端界面
- [ ] 能上传 PDF
- [ ] 能提问并获得答案

**评分**:
```
8/8 = 优秀 ✅
6-7/8 = 良好 👍
4-5/8 = 需要帮助 ⚠️
<4/8 = 需要重新开始 🔄
```

---

### 第二阶段评估

**理解程度**:
- [ ] 能解释 RAG 是什么
- [ ] 能画出系统架构图
- [ ] 能解释向量数据库的作用
- [ ] 能说出五个核心模块的功能
- [ ] 能描述两个主要流程
- [ ] 能解释事件驱动架构
- [ ] 能回答反思问题（见上）

**知识检查**:
```
问题 1: RAG 的三个阶段是什么？
你的答案: ___________________
正确答案: Retrieval, Augmentation, Generation

问题 2: 为什么要用向量数据库？
你的答案: ___________________
正确答案: 支持语义搜索，基于含义而不是关键词

问题 3: Inngest 的作用是什么？
你的答案: ___________________
正确答案: 事件驱动引擎，处理限流、重试、监控

问题 4: top_k 参数是什么？
你的答案: ___________________
正确答案: 返回最相似的 k 个段落数
```

**评分标准**:
```
4 题正确 = 理解充分 ✅
3 题正确 = 基本理解 👍
2 题正确 = 需要复习 ⚠️
<2 题 = 重新学习 🔄
```

---

### 第三阶段评估

**代码追踪能力**:

**测试 1: 上传一个 PDF，描述发生的事**
```
用户上传 PDF
  ↓
你写出接下来会发生的 5 个步骤:
1. _________________________
2. _________________________
3. _________________________
4. _________________________
5. _________________________

检查答案: 应该提到上传、分块、向量化、存储
```

**测试 2: 跟踪一个提问，描述数据流**
```
用户提问"什么是机器学习?"
  ↓
你写出接下来会调用的 API:
1. _________________________
2. _________________________
3. _________________________

检查答案: embedding API、search、chat API
```

**测试 3: 修改参数并预测结果**
```
把 chunk_size 从 1000 改为 500
  ↓
预测会发生什么:
- 块数会___（增加/减少）
- 搜索速度会___（变快/变慢）
- 准确度会___（提高/降低）

通过上传 PDF 并观察验证你的预测
```

**评分**:
```
3 个测试都通过 = 理解充分 ✅
2 个通过 = 基本理解 👍
1 个通过 = 需要复习 ⚠️
0 个通过 = 重新学习 🔄
```

---

### 第四阶段评估

**开发能力**:

**项目 1: 添加一个新功能**
```
要求:
- 选择一个功能（如显示搜索分数）
- 理解需要修改的文件
- 进行修改
- 测试新功能
- 写一个简单的文档

评分:
✅ 完成 = 优秀
⚠️ 部分完成 = 良好
❌ 未完成 = 需要帮助
```

**项目 2: 修复或改进一个功能**
```
要求:
- 找到一个可以改进的地方
- 分析原因
- 实现改进
- 测试改进效果
- 记录改进前后对比

评分标准同上
```

**项目 3: 性能分析**
```
要求:
- 测量各个步骤的耗时
- 找出瓶颈
- 提出优化方案
- 实施优化
- 对比结果

评分标准同上
```

---

### 第五阶段评估

**扩展能力**:

**完成一个大功能**
```
选择方向（多文档对比、高级提示工程等）
  ↓
分析需要的修改
  ↓
实施功能
  ↓
测试功能
  ↓
写文档
  ↓
部署和演示

评分:
✅ 完成并稳定 = 优秀
⚠️ 完成但有 bug = 良好
❌ 未完成 = 继续努力
```

---

## 常见学习陷阱

### 陷阱 1: "只读不练"

**问题**: 读了很多代码，但没有自己动手修改

**解决方案**:
```
✅ 每学完一个模块，立即进行实践
✅ 尝试修改参数看看效果
✅ 添加日志来追踪执行
✅ 在代码中添加注释说明
```

### 陷阱 2: "跳过基础，直接扩展"

**问题**: 跳过理解阶段，直接想添加新功能

**解决方案**:
```
✅ 按照阶段序列学习
✅ 完成每个阶段的评估
✅ 确保理解后再进行
✅ 不要跳跃
```

### 陷阱 3: "只看本地，忽视部署"

**问题**: 应用在本地工作，但部署到生产时失败

**解决方案**:
```
✅ 从开始就考虑部署
✅ 使用 Docker 本地测试
✅ 理解环境变量的重要性
✅ 实施日志和监控
```

### 陷阱 4: "API 调用太多，成本超支"

**问题**: 频繁调用 API 导致成本过高

**解决方案**:
```
✅ 理解 API 定价
✅ 在开发时使用较小的输入
✅ 实施缓存机制
✅ 监控 API 调用统计
✅ 定期检查成本

成本估计:
- embedding: $0.00000002 per token
- gpt-4o-mini: 输入 $0.15 per 1M tokens
                输出 $0.60 per 1M tokens

一个典型查询成本: $0.001-0.005
```

### 陷阱 5: "忽视错误处理"

**问题**: 代码只考虑正常路径，不处理错误

**解决方案**:
```
✅ 使用 try-except 处理异常
✅ 添加有用的错误消息
✅ 记录错误日志
✅ 实施重试机制
✅ 优雅降级

关键错误场景:
- API 超时
- 网络连接失败
- 无效的 PDF 文件
- 超出限流
- 超大文档
```

---

## 学习支持资源

### 推荐阅读顺序

1. **理论基础**
   - [ ] 阅读 `PROJECT_SPEC_CN.md` 第 1-3 章
   - [ ] 理解 RAG 概念
   - [ ] 理解向量数据库

2. **系统设计**
   - [ ] 阅读 `PROJECT_SPEC_CN.md` 第 4 章
   - [ ] 阅读 `PROJECT_SPEC_CN.md` 第 5 章
   - [ ] 理解数据流

3. **实践操作**
   - [ ] 阅读 `PROJECT_SPEC_CN.md` 第 6-7 章
   - [ ] 按步骤搭建环境
   - [ ] 运行应用

4. **生产部署**
   - [ ] 阅读 `PROJECT_SPEC_CN.md` 第 8 章
   - [ ] 理解部署方案
   - [ ] 尝试本地 Docker 部署

### 关键代码文件

| 文件 | 学习顺序 | 难度 | 时间 |
|------|---------|------|------|
| `custom_types.py` | 1 | ⭐ | 15 min |
| `data_loader.py` | 2 | ⭐⭐ | 30 min |
| `vector_db.py` | 3 | ⭐⭐ | 30 min |
| `streamlit_app.py` | 4 | ⭐⭐⭐ | 45 min |
| `main.py` | 5 | ⭐⭐⭐⭐ | 60 min |

### 学习方法建议

```
方法 1: 概览阅读
时间: 2-3 小时
步骤:
1. 快速浏览所有代码
2. 关注函数签名和注释
3. 不深入细节
目标: 建立整体认识

方法 2: 深入分析
时间: 5-8 小时
步骤:
1. 一行一行读代码
2. 追踪变量值
3. 理解每个操作
目标: 完全理解逻辑

方法 3: 实验修改
时间: 3-5 小时
步骤:
1. 修改参数
2. 添加日志
3. 观察效果
目标: 获得实战经验

方法 4: 教别人
时间: 2-3 小时
步骤:
1. 给别人讲解某个模块
2. 回答问题
3. 写教程或文档
目标: 验证和深化理解
```

---

## 学习进度追踪

### 周进度跟踪

```
第 1 周进度:
□ Day 1: 环境搭建
□ Day 2: 配置 API
□ Day 3: 启动应用
□ Day 4: 阅读规格
□ Day 5: 理解架构
□ Day 6: 追踪代码
□ Day 7: 测试功能

完成度: _____ / 7

第 2 周进度:
□ Day 1-2: 深入理解 PDF 流程
□ Day 3-4: 深入理解问答流程
□ Day 5: 理解 API 调用
□ Day 6: 理解向量搜索
□ Day 7: 整体复习

完成度: _____ / 7

...以此类推
```

---

## 总结

通过这个学习路线图，你将能够：

✅ **第一阶段后**: 环境搭建完成，应用正常运行
✅ **第二阶段后**: 理解系统架构，能解释各个模块
✅ **第三阶段后**: 能追踪代码执行，理解数据流向
✅ **第四阶段后**: 能修改和优化应用功能
✅ **第五阶段后**: 能添加新功能，扩展应用

**预期投入时间**: 4-6 周，每周 15-25 小时

**建议**:
- 🎯 设定明确的学习目标
- 📝 记录学习笔记
- 💻 每天都要动手实践
- 🤝 和他人讨论和交流
- 📊 定期检查进度

祝你学习顺利！

---

**文档版本**: 1.0
**最后更新**: 2025-11-16
**下一步**: 开始第一阶段 - 环境搭建！🚀
